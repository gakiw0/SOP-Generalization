from calendar import c
import json
import csv
import re
from pathlib import Path
import numpy as np
import similaritymeasures
from scipy.spatial.distance import directed_hausdorff
from scipy.stats import kendalltau
import matplotlib.pyplot as plt
import cv2
import os
import argparse
import pandas as pd

from PIL import Image, ImageDraw, ImageFont
from torch import res
import pandas as pd

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import numpy as np

# å»ºè­°çš„æœ‰å‘éª¨æ¶æ¨¹ï¼ˆOpenPose BODY_25ï¼‰
# ä»¥ 8(midHip) ç•¶å…¨èº« rootï¼Œç”±å…§å‘å¤–å±•é–‹
DIRECTED_BONES = [
    (8, 1),            # torso up
    (1, 0),            # neck->head
    (0, 15), (15, 17), # head left chain
    (0, 16), (16, 18), # head right chain

    (1, 2), (2, 3), (3, 4),  # right arm (OpenPose index 2/3/4)
    (1, 5), (5, 6), (6, 7),  # left arm  (OpenPose index 5/6/7)

    (8, 9), (9, 10), (10, 11), (11, 24), (11, 22), (22, 23),  # right leg+foot
    (8, 12), (12, 13), (13, 14), (14, 21), (14, 19), (19, 20) # left  leg+foot
]

def _safe_unit(v):
    """å›å‚³å–®ä½å‘é‡ï¼›è‹¥é•·åº¦ç‚º 0 æˆ–æœ‰ NaNï¼Œå›å‚³ Noneã€‚"""
    if v is None: return None
    if np.any(np.isnan(v)): return None
    n = np.linalg.norm(v)
    if n <= 1e-12: return None
    return v / n



def _bone_length(arr, i, j):
    """é» j åˆ°é» i çš„é•·åº¦ï¼ˆarr: (25,3) å–®å¹€é—œç¯€ï¼‰ã€‚"""
    if np.any(np.isnan(arr[i])) or np.any(np.isnan(arr[j])): 
        return None
    return np.linalg.norm(arr[j] - arr[i])

def _compute_target_lengths(coach, use_avg_lengths=False):
    """
    ç”¢ç”Ÿ target é•·åº¦ï¼š
    - use_avg_lengths=False: é€å¹€ç”¨æ•™ç·´å°æ‡‰éª¨éª¼é•·åº¦ï¼ˆå‹•æ…‹ï¼‰
    - True: ç”¨æ•™ç·´å…¨ç‰‡å¹³å‡é•·åº¦ï¼ˆéœæ…‹ï¼‰
    å›å‚³ shape = (frames, len(DIRECTED_BONES))
    """
    F = coach.shape[0]
    B = len(DIRECTED_BONES)
    tgt = np.zeros((F, B), dtype=float)

    if use_avg_lengths:
        # å…ˆè¨ˆç®—æ¯æ¢éª¨éª¼åœ¨æ•™ç·´å½±ç‰‡ä¸­çš„å¹³å‡é•·åº¦
        avg_len = np.zeros(B, dtype=float)
        for b_idx, (p, c) in enumerate(DIRECTED_BONES):
            lens = []
            for f in range(F):
                L = _bone_length(coach[f], p, c)
                if L is not None:
                    lens.append(L)
            avg_len[b_idx] = np.mean(lens) if len(lens) else 0.0
        tgt[:] = avg_len[None, :]  # å…¨å¹€ä½¿ç”¨åŒä¸€çµ„å¹³å‡é•·åº¦
    else:
        # é€å¹€é•·åº¦
        for f in range(F):
            for b_idx, (p, c) in enumerate(DIRECTED_BONES):
                L = _bone_length(coach[f], p, c)
                tgt[f, b_idx] = 0.0 if (L is None) else L
    return tgt

def normalize_student_to_coach_lengths(student: np.ndarray,
                                       coach: np.ndarray,
                                       keep_root_xyz=True,
                                       use_avg_lengths=False) -> np.ndarray:
    """
    ä¾ç…§æ•™ç·´çš„éª¨éª¼é•·åº¦ï¼Œå°‡å­¸ç”Ÿæ¯æ¢éª¨éª¼æ²¿åŸæ–¹å‘ä¼¸ç¸®åˆ°ç›¸åŒé•·åº¦ã€‚
    - ç”± 8(midHip) ç‚º rootï¼Œä¾ DIRECTED_BONES ç”±å…§å‘å¤–æ¨ç®—
    - keep_root_xyz=Trueï¼šä¿ç•™ root(8) çš„åŸå§‹ä½ç½®ï¼ˆåƒ…å­ç¯€é»è¢«é‡ç®—ï¼‰
    - use_avg_lengths=Trueï¼šç”¨æ•™ç·´å…¨ç‰‡å¹³å‡é•·åº¦ï¼›Falseï¼šé€å¹€é•·åº¦
    å›å‚³ï¼šèˆ‡ student åŒå½¢ç‹€çš„æ–° arrayï¼ˆ(frames, 25, 3)ï¼‰
    """
    assert student.shape == coach.shape and student.shape[1] >= 25 and student.shape[2] == 3
    F = student.shape[0]
    out = student.copy()

    # ç›®æ¨™é•·åº¦è¡¨
    tgt_lens = _compute_target_lengths(coach, use_avg_lengths=use_avg_lengths)

    for f in range(F):
        frame = out[f]

        # 1) é–ä½ rootï¼ˆ8ï¼‰ä½ç½®ï¼šå¯é¸æ“‡ä¿ç•™æˆ–ç½®ä¸­åˆ°åŸé»
        if keep_root_xyz:
            root_pos = frame[8].copy()
        else:
            # è‹¥ä½ æƒ³æŠŠ 8 æ”¾åˆ°åŸé»ï¼Œå¯æ”¹æˆï¼š
            # root_pos = np.zeros(3, dtype=float)
            root_pos = frame[8].copy()

        # 2) ç”±å…§å‘å¤–é‡å»ºï¼šæ¯æ¢éª¨éª¼åªæ”¹ child
        #    æ³¨æ„ï¼šåŒä¸€ child å¯èƒ½æ˜¯å¤šåˆ†æ”¯æœ«ç«¯ä¹‹ä¸€ï¼Œä½†åœ¨æ­¤æœ‰å‘æ¨¹è£¡ï¼Œæ¯å€‹ child åªæœ‰ä¸€å€‹ parent
        frame[8] = root_pos  # å›ºå®š root

        for b_idx, (p, c) in enumerate(DIRECTED_BONES):
            parent = frame[p]
            child  = frame[c]

            # parent å°šæœªå®šç¾©ï¼ˆæˆ– NaNï¼‰å°±è·³é
            if np.any(np.isnan(parent)) or np.any(np.isnan(child)):
                continue

            # å–ã€Œå­¸ç”ŸåŸå…ˆçš„æ–¹å‘ã€
            dir_vec = _safe_unit(child - parent)
            if dir_vec is None:
                # ç„¡æ³•æ±ºå®šæ–¹å‘ â†’ ä¿ç•™åŸ child
                continue

            L = tgt_lens[f, b_idx]
            if L <= 0:
                # æ²’æœ‰åˆç†çš„ç›®æ¨™é•·åº¦ â†’ ä¸å‹•
                continue

            # é‡æ–°è¨­å®š childï¼šparent + åŸæ–¹å‘ * æ•™ç·´ç›®æ¨™é•·åº¦
            frame[c] = parent + dir_vec * L

        out[f] = frame

    return out

OPENPOSE_CONNECTIONS = [
    (0, 16), (0, 15), (15, 17), (16, 18), #face
    (0, 1), #neck
    (1, 8), #body 
    (1, 5), (5, 6), (6, 7), #left arm
    (1, 2), (2, 3), (3, 4), #right arm
    (8, 9), (8, 12), #hips
    (12, 13), (13, 14), #left leg
    (14, 21), (14, 19), (19, 20), #left foot
    (9, 10), (10, 11), #right leg
    (11, 24), (11, 22), (22, 23) # right foot
]
REPO_ROOT = Path(__file__).resolve().parents[1]
_DEFAULT_DATA_ROOT = REPO_ROOT / "datasets" / "EZmocap" / "CASA_outputs"
_SIBLING_DATA_ROOT = REPO_ROOT.parent / "Data" / "datasets" / "EZmocap" / "CASA_outputs"
_ENV_DATA_ROOT = os.environ.get("SOP_DATA_ROOT")
if _ENV_DATA_ROOT:
    DATA_ROOT = Path(_ENV_DATA_ROOT)
elif _SIBLING_DATA_ROOT.exists():
    DATA_ROOT = _SIBLING_DATA_ROOT
else:
    DATA_ROOT = _DEFAULT_DATA_ROOT
ANALYSIS_ROOT = REPO_ROOT / "datasets" / "EZmocap" / "Analysis_results"

def load_json(file_path):
    with open(file_path, 'r') as file:
        return json.load(file)
def extract_skeleton_joints(data, frames, joints):
    result = []
    for frame in frames:
        for joint in joints:
            result.append(data[frame][joint])
    return np.array(result)

def extract_skeleton_data(data, frames):
    result = []
    for frame in frames:
        # print(f"Extracting frame {frame} data: {data[frame].shape}")    
        result.append(data[frame])
    return np.array(result)
def calculate_frechet_distance(data1, data2):
    return similaritymeasures.frechet_dist(data1, data2)
def calculate_hausdorff_distance(data1, data2):
    d1, idx1, idx1_match = directed_hausdorff(data1, data2)
    d2, idx2, idx2_match = directed_hausdorff(data2, data1)

    ## idx å¯ä»¥çŸ¥é“æ˜¯å“ªä¸€å€‹jointå·®æœ€å¤š
    return max(d1, d2)
def calculate_kendalls_tau(data1, data2):
    def get_motion_magnitude(data):
        return [np.linalg.norm(data[i+1] - data[i]) for i in range(len(data)-1)]
    mag1 = get_motion_magnitude(data1)
    mag2 = get_motion_magnitude(data2)
    min_len = min(len(mag1), len(mag2))
    tau, _ = kendalltau(mag1[:min_len], mag2[:min_len])
    return tau

def generate_feedback(frechet_percent, hausdorff_percent, kendall_percent):

    # å€‹åˆ¥å›é¥‹
    if frechet_percent > 80:
        frechet_feedback = "-Motion smoothness: stable"
    elif frechet_percent > 60:
        frechet_feedback = "-Motion smoothness: slightly off"
    else:
        frechet_feedback = "-Motion smoothness: needs improvement"

    if hausdorff_percent > 80:
        hausdorff_feedback = "-Pose accuracy: good"
    elif hausdorff_percent > 60:
        hausdorff_feedback = "-Pose accuracy: slightly off"
    else:
        hausdorff_feedback = "-Pose accuracy: needs correction"

    if kendall_percent > 80:
        kendall_feedback = "-Motion timing/order: consistent"
    elif kendall_percent > 60:
        kendall_feedback = "-Motion timing/order: slightly different"
    else:
        kendall_feedback = "-Motion timing/order: needs correction"

    # Overall è©•èªï¼šé¸æœ€ä½ percent ä¾†çµ¦çµè«–
    min_percent = min(frechet_percent, hausdorff_percent, kendall_percent)
    if min_percent > 80:
        overall = "Overall motion looks good."
    elif min_percent > 60:
        overall = "Overall is OK; adjust details."
    else:
        overall = "Overall needs improvement; focus on fundamentals."

    return frechet_feedback, hausdorff_feedback, kendall_feedback, overall


# def parse_score(value):
#     """è½‰æ›å¸¶æœ‰é¡è‰²æ¨™è¨˜çš„æ–‡å­—æˆåˆ†æ•¸ (0-100)"""
#     if "(green)" in value:
#         return 100
#     elif "(lerp(yellowâ†’red:" in value:
#         try:
#             num = float(value.split(":")[-1].strip("))"))
#             return int(100 * (1 - num))  # å€¼è¶Šå¤§åˆ†è¶Šä½
#         except:
#             return 50
#     elif "(yellow)" in value:
#         return 60
#     elif "(red)" in value:
#         return 30
#     else:
#         return 50  # default fallback
def parse_score(value):
    """è½‰æ›å¸¶æœ‰é¡è‰²æ¨™è¨˜çš„æ–‡å­—æˆåˆ†æ•¸ (0-100)"""
    if "(green)" in value:
        return 100
    elif "(yellow)" in value:
        return 60
    elif "(red)" in value:
        return 30
    else:
        return 50  # default fallback




def classify_step(biomech_colors):
    if len(biomech_colors) == 1:
        color = biomech_colors[0]
        return "correct" if "green" in color else "wrong" if "red" in color else "mid"
    if all("green" in c for c in biomech_colors):
        return "correct"
    elif all("red" in c for c in biomech_colors):
        return "wrong"
    return "mid"

def save_analysis_results(data_name, analysis_results, step_ranges):
    step_output_path = DATA_ROOT / data_name / "aligned" / "step_frame_ranges.json"
    output_dict_path = DATA_ROOT / data_name / "analysis_results.json"

    with open(step_output_path, 'w') as f:
        json.dump(step_ranges, f, indent=4)
    with open(output_dict_path, 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, ensure_ascii=False, indent=2)

    print(f"âœ… åˆ†æçµæœå·²è¼¸å‡ºè‡³ {output_dict_path}")

def similarity_percentages(frechet: float, hausdorff: float, kendall_tau: float) -> dict:
    """
    å°‡ Frechet è·é›¢ã€Hausdorff è·é›¢ã€Kendall's Tau è½‰æ›ç‚º 0~100 çš„ç›¸ä¼¼åº¦ç™¾åˆ†æ¯”

    å‚³å…¥ï¼š
        frechet: Frechet distance (è¶Šå°è¶Šå¥½)
        hausdorff: Hausdorff distance (è¶Šå°è¶Šå¥½)
        kendall_tau: Kendall's Tau (è¶Šæ¥è¿‘ 1 è¶Šå¥½)

    å›å‚³ï¼š
        å­—å…¸ï¼ŒåŒ…å« frechet_percent, hausdorff_percent, kendall_percent
    """
    # å¯æ ¹æ“šå¯¦é©—èª¿æ•´çš„æœ€å¤§å®¹å¿è·é›¢ï¼Œè¶…éå°±è¦–ç‚º 0%
    FRECHET_MAX = 5.0
    HAUSDORFF_MAX = 5.0

    # Frechet/Hausdorff è·é›¢çš„ç·šæ€§åæ¯”è½‰æ›
    frechet_percent = max(0, 100 * (1 - frechet / FRECHET_MAX))
    hausdorff_percent = max(0, 100 * (1 - hausdorff / HAUSDORFF_MAX))

    # Kendall's Tau æœ¬èº«å°±ä»‹æ–¼ -1 ~ 1ï¼Œé€šå¸¸åªå– 0~1
    kendall_percent = max(0, min(1.0, kendall_tau)) * 100

    return round(frechet_percent, 1),round(hausdorff_percent, 1), round(kendall_percent, 1)
    
def split_video_by_steps(video_path, output_folder, steps, cam_id):
    """
    å°‡å½±ç‰‡ä¾æ“šæŒ‡å®šçš„æ­¥é©Ÿ frame ç¯„åœé€²è¡Œåˆ‡å‰²ï¼Œæ¯æ­¥é©Ÿè¼¸å‡ºä¸€å€‹å½±ç‰‡ã€‚

    :param video_path: è¦è™•ç†çš„å½±ç‰‡è·¯å¾‘
    :param output_folder: è¼¸å‡ºè³‡æ–™å¤¾
    :param steps: æ¯å€‹æ­¥é©Ÿçš„ frame ç¯„åœ
    :param cam_id: ç›¸æ©Ÿç·¨è™Ÿï¼ˆç”¨æ–¼æª”åï¼‰
    """
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"âŒ ç„¡æ³•æ‰“é–‹å½±ç‰‡: {video_path}")
        return

    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    for step_idx, (step_name, (frame_range, _)) in enumerate(steps.items(), start=1):
        output_path = Path(output_folder) / f"step{step_idx}_cam{cam_id}.mp4"
        out = cv2.VideoWriter(str(output_path), cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))
        print(f"ğŸ“¤ è¼¸å‡º: {output_path} ({frame_range[0]} ~ {frame_range[-1]})")

        for frame_idx in range(frame_range[0], frame_range[-1] + 1):
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if not ret:
                print(f"âš ï¸ ç„¡æ³•è®€å– frame {frame_idx}ï¼Œè·³é")
                continue
            out.write(frame)

        out.release()

    cap.release()
    print(f"âœ… å·²å®Œæˆå½±ç‰‡åˆ‡å‰²ï¼š{video_path}")

def split_data_by_steps(data, steps, output_name, output_folder):
    """
    æ ¹æ“šæ­¥é©Ÿçš„ frame rangeï¼Œåˆ†å‰² data ä¸¦å­˜æˆå°æ‡‰ JSON æª”æ¡ˆã€‚

    :param data: numpy arrayï¼Œå½¢ç‹€ç‚º (frame, joint, dim)
    :param steps: dictï¼Œæ¯æ­¥ç‚º (frame_range, joint_indices)ï¼Œä½†æ­¤ç‰ˆæœ¬ä¸æœƒç”¨åˆ° joint_indices
    :param output_name: è¼¸å‡ºæª”æ¡ˆå‘½åçš„å‰ç¶´
    :param output_folder: å„²å­˜è³‡æ–™å¤¾
    """
    print(f"ğŸ“Š åˆ†ææ•¸æ“šï¼Œç¸½å¹€æ•¸: {len(data)}")
    print(f"Data shape: {data.shape}")
    os.makedirs(output_folder, exist_ok=True)

    for idx, (step_name, (frame_range, _)) in enumerate(steps.items(), start=1):
        step_frames = data[frame_range[0]:frame_range[-1] + 1]
        print(f"âœ‚ï¸ Step {idx}: {step_name} â†’ shape = {step_frames.shape}")

        # å„²å­˜ JSON
        output_path = Path(output_folder) / f"step{idx}_{output_name}.json"
        with open(output_path, 'w') as f:
            json.dump(step_frames.tolist(), f, indent=4)
            print(f"âœ… å·²å„²å­˜ {step_name} æ•¸æ“šè‡³ {output_path}")

def split_all_videos_by_steps(data_name, steps):
    for cam_id in range(1, 5):
        for role in ["student", "coach"]:
            video_path = DATA_ROOT / data_name / "aligned" / f"{role}_video" / f"cam{cam_id}_aligned.mp4"
            output_folder = DATA_ROOT / data_name / "aligned" / f"{role}_video"
            split_video_by_steps(video_path, output_folder, steps, cam_id)

def split_all_data_by_steps(data_name, steps):
    data_output_folder = DATA_ROOT / data_name / "aligned" / "data"
    data_files = {
        "student_aligned_skeleton": data_output_folder / "student_aligned_skeleton.json",
        "coach_aligned_skeleton": data_output_folder / "coach_aligned_skeleton.json",
        "student_aligned_bat": data_output_folder / "student_aligned_bat.json",
        "coach_aligned_bat": data_output_folder / "coach_aligned_bat.json"
    }

    for name, path in data_files.items():
        data = np.array(load_json(path))
        split_data_by_steps(data, steps, name, data_output_folder)


def update_color(val, tolerance=0.1, mid_ratio=3.0, abs_val=True):
    """
    ä½¿ç”¨èª¤å·®å®¹å¿ç¯„åœï¼ˆtoleranceï¼‰èˆ‡ä¸­é–“å¸¶å€ç‡ï¼ˆmid_ratioï¼‰å®šç¾©é¡è‰²å€é–“ã€‚

    - ç¶ è‰²ï¼š val <= tolerance
    - é»ƒè‰²ï¼š tolerance < val <= tolerance * mid_ratio
    - ç´…è‰²ï¼š val > tolerance * mid_ratio
    """
    val = abs(val) if abs_val else val
    if val <= tolerance:
        return (0, 255, 0), "green"
    elif val <= tolerance * mid_ratio:
        return (255, 255, 0), "yellow"
    else:
        return (255, 0, 0), "red"

# def get_general_motion_feedback_level(val: float, tolerance: float = 0.1, abs_val: bool = True) -> str:
#     val = abs(val) if abs_val else val
#     if val <= tolerance:
#         return "æ­£ç¢º"
#     elif val <= 0.2:
#         return "é©ç•¶"
#     elif val <= 0.5:
#         return "åå·®ç¨å¤§"
#     elif val <= 1.0:
#         return "å·®ç•°éå¤§"
#     else:
#         return "åš´é‡éŒ¯èª¤"

def xyzout(point, i):
    # æ ¹æ“š i å€¼ï¼Œå°‡ point æŠ•å½±åˆ°æŸå€‹å¹³é¢
    if np.any(np.isnan(point)):
        return np.array([0, 0, 0])

    if i == 0:
        return np.array([0, point[1], point[2]])  # å»é™¤ x åˆ†é‡ï¼ŒæŠ•å½±åˆ° YZ å¹³é¢
    elif i == 1:
        return np.array([point[0], 0, point[2]])  # å»é™¤ y åˆ†é‡ï¼ŒæŠ•å½±åˆ° XZ å¹³é¢
    elif i == 2:
        return np.array([point[0], point[1], 0])  # å»é™¤ z åˆ†é‡ï¼ŒæŠ•å½±åˆ° XY å¹³é¢
    return point  # è‹¥ i ä¸ç‚º 0~2ï¼ŒåŸæ¨£å›å‚³
def angle_between(v1, v2):
    unit_v1 = v1 / np.linalg.norm(v1)  # å–®ä½åŒ– v1
    unit_v2 = v2 / np.linalg.norm(v2)  # å–®ä½åŒ– v2
    dot_product = np.clip(np.dot(unit_v1, unit_v2), -1.0, 1.0)  # å…§ç©çµæœé™åˆ¶åœ¨ [-1, 1] é¿å…èª¤å·®
    return np.degrees(np.arccos(dot_product))  # å›å‚³å¤¾è§’ï¼ˆå–®ä½ï¼šåº¦ï¼‰
def get_angle_with_xz_plane(vec: np.ndarray) -> float:
    """
    è¨ˆç®—ä¸€å€‹å‘é‡èˆ‡ XZ å¹³é¢çš„å¤¾è§’ï¼Œä½¿ç”¨ angle_between()
    """
    vec_proj = np.array([vec[0], 0.0, vec[2]])  # æŠ•å½±åˆ° XZ å¹³é¢ï¼ˆY åˆ†é‡è¨­ç‚º 0ï¼‰
    return angle_between(vec, vec_proj)

def compute_shoulder_angle(joints: np.ndarray) -> float:
    """
    è¨ˆç®—å·¦å³è‚©è†€çš„å‚¾æ–œè§’åº¦ï¼ˆä»¥ Y å·® / X å·® â†’ atan2ï¼‰
    å›å‚³è§’åº¦ï¼ˆdegreesï¼‰ï¼Œè‹¥å®Œå…¨æ°´å¹³å‰‡ç‚º 0Â°
    """
    right_shoulder = joints[2]
    left_shoulder = joints[5]

    dy = right_shoulder[1] - left_shoulder[1]
    dx = right_shoulder[0] - left_shoulder[0]
    angle_rad = np.arctan2(dy, dx)
    angle_deg = np.degrees(angle_rad)
    return angle_deg

def get_center_of_gravity(skeleton: np.ndarray, frame='avg', project='none') -> np.ndarray:
    """
    è¨ˆç®—ä¸­å¿ƒé» (neck + midhip)/2 ä½œç‚ºé‡å¿ƒåƒè€ƒã€‚

    Args:
        skeleton: shape (frames, 25, 3)
        frame: 'avg' ä½¿ç”¨æ•´æ®µå¹³å‡ï¼Œæˆ–å‚³å…¥æŒ‡å®š frame index
        project: 'xz' åƒ…ä¿ç•™ X,Z åˆ†é‡ï¼›'none' ä¿ç•™åŸå§‹ XYZ

    Returns:
        np.ndarray shape (3,) æˆ– (2,) çš„é‡å¿ƒåº§æ¨™
    """
    if isinstance(frame, int):
        neck = skeleton[frame, 1]
        midhip = skeleton[frame, 8]
    elif frame == 'avg':
        neck = np.mean(skeleton[:, 1], axis=0)
        midhip = np.mean(skeleton[:, 8], axis=0)
    else:
        raise ValueError(f"Unsupported frame value: {frame}")

    cog = (neck + midhip) / 2

    if project == 'xz':
        return np.array([cog[0], cog[2]])
    return cog

def get_center_of_gravity_midhip_only(skeleton: np.ndarray, frame='avg', project='none') -> np.ndarray:
    """
    ä½¿ç”¨ joint 8ï¼ˆMidHipï¼‰ä½œç‚ºé‡å¿ƒåƒè€ƒé»ã€‚

    Args:
        skeleton: shape (frames, 25, 3)
        frame: 'avg' ä½¿ç”¨æ•´æ®µå¹³å‡ï¼Œæˆ–å‚³å…¥æŒ‡å®š frame index
        project: 'xz' åƒ…ä¿ç•™ X,Z åˆ†é‡ï¼›'none' ä¿ç•™åŸå§‹ XYZ

    Returns:
        np.ndarray shape (3,) æˆ– (2,) çš„é‡å¿ƒåº§æ¨™
    """
    if isinstance(frame, int):
        cog = skeleton[frame, 8]
    elif frame == 'avg':
        cog = np.mean(skeleton[:, 8], axis=0)
    else:
        raise ValueError(f"Unsupported frame value: {frame}")

    if project == 'xz':
        return np.array([cog[0], cog[2]])
    return cog


def get_relative_cg_position(skeleton: np.ndarray, frame='avg', axis='z', midhipOnly=False) -> float:
    """
    è¨ˆç®—é‡å¿ƒç›¸å°æ–¼è…³è¸ä¸­å¿ƒåœ¨ XZ å¹³é¢ä¸Šçš„åç§»é‡ï¼ˆX æˆ– Z è»¸ï¼‰

    Args:
        skeleton: (frames, 25, 3)
        frame: 'avg' æˆ– int
        axis: 'x' or 'z'
        midhipOnly: è‹¥ç‚º Trueï¼Œåƒ…ä½¿ç”¨ joint 8ï¼ˆMidHipï¼‰ä½œç‚ºé‡å¿ƒåƒè€ƒ

    Returns:
        float: æ­£å€¼è¡¨ç¤ºåå‰/å³ï¼Œè² å€¼è¡¨ç¤ºåå¾Œ/å·¦
    """
    if midhipOnly:
        # æ”¹ç”¨ MidHip-only ç•¶ä½œé‡å¿ƒ
        if isinstance(frame, int):
            cog = skeleton[frame, 8]
        elif frame == 'avg':
            cog = np.mean(skeleton[:, 8], axis=0)
        else:
            raise ValueError(f"Unsupported frame value: {frame}")
        cg = cog[[0, 2]]  # å– x, z
    else:
        cg = get_center_of_gravity(skeleton, frame=frame, project='xz')

    if isinstance(frame, int):
        joints = skeleton[frame]
    elif frame == 'avg':
        joints = np.mean(skeleton, axis=0)
    else:
        raise ValueError(f"Unsupported frame value: {frame}")

    foot_center_3d = (joints[11] + joints[14]) / 2
    foot_center = foot_center_3d[[0, 2]]  # å– x, z

    axis_idx = {'x': 0, 'z': 1}[axis]  # x å°æ‡‰ç´¢å¼• 0ï¼Œz å°æ‡‰ç´¢å¼• 1
    return cg[axis_idx] - foot_center[axis_idx]

def export_all_data_checkpoints_to_csv(all_analysis_results, data_names, output_csv_path):
    """
    å°‡æ‰€æœ‰è³‡æ–™çš„åˆ†æçµæœï¼ˆæ¯å€‹æ­¥é©Ÿçš„æ¯å€‹ checkpointï¼‰æ•´åˆæˆä¸€ä»½ CSVï¼Œæ ¼å¼é¡ä¼¼åŸå§‹ XLSX è©•åˆ†è¡¨ã€‚

    Args:
        all_analysis_results (dict): dict of {data_name: analysis_result_dict}
        data_names (list): è³‡æ–™åç¨±é †åº
        output_csv_path (str): è¼¸å‡º CSV æª”æ¡ˆè·¯å¾‘
    """
    rows = []
    header = ["SOP Checklist"] + data_names

    for step_name in ["Step1", "Step2", "Step3", "Step4"]:
        # rows.append([step_name])  # Step æ¨™é¡Œåˆ—

        # æ”¶é›†æ‰€æœ‰è³‡æ–™ä¸­è©² step çš„ checkpoint åç¨±ï¼ˆç…§ç¬¬ä¸€ç­†è³‡æ–™æŠ“ï¼‰
        checkpoints = []
        for key in all_analysis_results[data_names[0]][step_name].keys():
            if key not in ["Frechet", "Hausdorff", "Kendall's Tau", "Feedback", "IsImportant", "Score", "StepTitle", "StepDescription", "StepClassification"]:
                checkpoints.append(key)

        for cp in checkpoints:
            row = [f"cp. {cp}"]
            for data_name in data_names:
                value = str(all_analysis_results[data_name][step_name].get(cp, ""))
                if "(green)" in value or "æ­£ç¢º" in value:
                    score_val = 1
                elif "(red)" in value or "å·®ç•°éå¤§" in value or "éŒ¯èª¤" in value:
                    score_val = -1
                elif "å°šå¯æ¥å—" in value or "(yellow)" in value:
                    score_val = 0
                else:
                    score_val = 0
                row.append(score_val)
            rows.append(row)

    df = pd.DataFrame(rows, columns=header)
    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
    print(f"ğŸ“„ å·²è¼¸å‡ºæ‰€æœ‰ checkpoint åˆ†æçµæœè‡³ {output_csv_path}")

def compute_per_checkpoint_accuracy(gt_csv_path, pred_csv_path):
    """
    è¨ˆç®—æ¯å€‹ checkpoint çš„æº–ç¢ºç‡ï¼Œä¸¦æ¨™è¨˜éŒ¯èª¤æ–¹å‘ï¼ˆé«˜ä¼° or ä½ä¼°ï¼‰ã€‚

    Returns:
        DataFrame: æ¯å€‹ checkpoint çš„æ­£ç¢ºæ•¸ã€éŒ¯èª¤æ•¸ã€æº–ç¢ºç‡ã€éŒ¯èª¤åå‘
    """
    gt_df = pd.read_csv(gt_csv_path).set_index("SOP Checklist")
    pred_df = pd.read_csv(pred_csv_path).set_index("SOP Checklist")

    cp_rows = [idx for idx in gt_df.index if str(idx).startswith("cp.")]
    gt_cp = gt_df.loc[cp_rows]
    pred_cp = pred_df.loc[cp_rows]
    common_cols = list(set(gt_cp.columns) & set(pred_cp.columns))

    records = []
    for cp in cp_rows:
        correct = 0
        total = 0
        over = 0  # é æ¸¬ > æ¨™æº–
        under = 0  # é æ¸¬ < æ¨™æº–

        over_list = []
        under_list = []

        for col in common_cols:
            gt_val = gt_cp.at[cp, col]
            pred_val = pred_cp.at[cp, col]
            if pd.isna(gt_val) or pd.isna(pred_val):
                continue
            gt_val = int(gt_val)
            pred_val = int(pred_val)

            if gt_val == pred_val:
                correct += 1
            elif pred_val > gt_val:
                over += 1
                over_list.append(col)
            elif pred_val < gt_val:
                under += 1
                under_list.append(col)
            total += 1

        accuracy = round(correct / total * 100, 1) if total > 0 else None
        bias = "åˆ†æ•¸åé«˜(å¤ªå¯¬é¬†)" if over > under else "åˆ†æ•¸åä½(å¤ªåš´æ ¼)" if under > over else "æ··åˆ(éœ€å¾®èª¿)"
        if over == 0 and under == 0:
            bias = "æº–ç¢º"

        records.append({
        "Checkpoint": cp,
        "Correct": correct,
        "Total": total,
        "Accuracy (%)": accuracy,
        "éŒ¯èª¤åå‘": bias,
        "Overestimates": ", ".join(over_list),
        "Underestimates": ", ".join(under_list),
        })

    return pd.DataFrame(records)

def set_axes_equal_3d(ax, points):
    """
    å¼·åˆ¶ ax ç­‰æ¯”ä¾‹é¡¯ç¤ºï¼Œæ ¹æ“šæ‰€æœ‰é»å»ºç«‹ç«‹æ–¹é«”é‚Šç•Œ
    """
    x = points[:, 0]
    y = points[:, 1]
    z = points[:, 2]

    x_range = x.max() - x.min()
    y_range = y.max() - y.min()
    z_range = z.max() - z.min()
    max_range = max(x_range, y_range, z_range) / 2.0

    x_center = (x.max() + x.min()) / 2
    y_center = (y.max() + y.min()) / 2
    z_center = (z.max() + z.min()) / 2

    ax.set_xlim(x_center - max_range, x_center + max_range)
    ax.set_ylim(y_center - max_range, y_center + max_range)
    ax.set_zlim(z_center - max_range, z_center + max_range)

def visualize_first_frame_with_axes(student_data, coach_data, data_name, output_dir="skeleton_vis"):
    os.makedirs(output_dir, exist_ok=True)

    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    ax.set_title(f"{data_name} - First Frame Skeletons")
    ax.view_init(elev=135, azim=135)

    def draw_skeleton(points, color, label):
        for i, j in OPENPOSE_CONNECTIONS:
            if i < len(points) and j < len(points):
                x = [points[i][0], points[j][0]]
                y = [points[i][1], points[j][1]]
                z = [points[i][2], points[j][2]]
                ax.plot(x, y, z, color=color, linewidth=2, alpha=0.9)
        ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=color, label=label, s=15)
        for i, (x, y, z) in enumerate(points):
            ax.text(x + 0.01, y + 0.01, z + 0.01, str(i), color='black', fontsize=8)

    student_frame = student_data[40]
    coach_frame = coach_data[40]

    draw_skeleton(student_frame, color='purple', label='Student')
    draw_skeleton(coach_frame, color='orange', label='Coach')

    # ç•«ç°¡çŸ­ RGB è»¸
    origin = [0, 0, 0]
    axis_len = 1
    ax.quiver(*origin, axis_len, 0, 0, color='r')  # X è»¸ï¼šç´…
    ax.quiver(*origin, 0, axis_len, 0, color='g')  # Y è»¸ï¼šç¶ 
    ax.quiver(*origin, 0, 0, axis_len, color='b')  # Z è»¸ï¼šè—

    # è¨­å®šç­‰æ¯”ä¾‹æ¡†æ¶ï¼ˆå« Student + Coachï¼‰
    all_points = np.concatenate([student_frame, coach_frame], axis=0)
    set_axes_equal_3d(ax, all_points)

    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    ax.legend()

    # if data_name =='bs1353':
    #     plt.show()
    plt.savefig(f"{output_dir}/{data_name}_first_frame_skeleton.png")
    plt.close()
    print(f"âœ… å·²å„²å­˜éª¨æ¶åœ–åƒï¼š{output_dir}/{data_name}_first_frame_skeleton.png")


from scipy.spatial.transform import Rotation as R
import numpy as np

def align_skeleton_orientation(joints: np.ndarray) -> np.ndarray:
    """
    å°‡ skeleton (frame, 25, 3) å°é½Šï¼š
    - pelvis vector (9â†’12) çš„ XZ æŠ•å½±å°é½Š Z è»¸
    - è‹¥è…³æŒ 11â†’22 æŒ‡å‘ X è² å‘ï¼Œå‰‡å†ç¹ Y è»¸æ—‹è½‰ 180Â°
    """
    aligned = joints.copy()

    # ç¬¬0å¹€ pelvis å‘é‡
    pelvis_vec = aligned[0][12] - aligned[0][9]
    pelvis_proj = np.array([pelvis_vec[0], 0, pelvis_vec[2]])  # æŠ•å½±åˆ° XZ å¹³é¢
    pelvis_proj /= np.linalg.norm(pelvis_proj)

    # ç›®æ¨™æ–¹å‘ï¼šZ è»¸ (0, 0, 1)
    target = np.array([0, 0, 1])
    angle = np.arccos(np.clip(np.dot(pelvis_proj, target), -1.0, 1.0))
    cross = np.cross(pelvis_proj, target)

    if cross[1] < 0:  # æ–¹å‘åˆ¤æ–·ï¼ˆY è»¸ç‚ºæ—‹è½‰è»¸ï¼‰
        angle = -angle

    R_y = R.from_euler('y', angle).as_matrix()
    aligned = aligned @ R_y.T

    # foot direction: 11â†’22
    foot_vec = aligned[0][22] - aligned[0][11]
    foot_vec = foot_vec / np.linalg.norm(foot_vec)
    if foot_vec[0] < 0:  # æŒ‡å‘ X è² å‘
        R_flip = R.from_euler('y', 180, degrees=True).as_matrix()
        aligned = aligned @ R_flip.T
    
    # å¹³ç§»ï¼šè®“ joint[8] çš„ XZ å¹³é¢ä½ç½®ç‚ºåŸé»
    xz_offset = aligned[0][8].copy()
    xz_offset[1] = 0  # ä¿ç•™ Y è»¸ä¸å‹•
    aligned = aligned - xz_offset  # broadcast

    return aligned
